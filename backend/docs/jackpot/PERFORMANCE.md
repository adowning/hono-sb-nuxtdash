# Jackpot Service Performance Tuning Guide

## Overview

This guide provides comprehensive strategies for optimizing the jackpot service performance, covering database tuning, application optimization, caching strategies, and monitoring approaches. It includes specific benchmarks, tuning parameters, and optimization techniques for high-throughput scenarios.

## Performance Benchmarks

### Target Performance Metrics

| Operation | Target Response Time | Warning Threshold | Critical Threshold |
|-----------|---------------------|-------------------|-------------------|
| Jackpot Contribution | < 100ms | > 200ms | > 500ms |
| Jackpot Win Processing | < 150ms | > 300ms | > 1000ms |
| Pool Retrieval (Single) | < 50ms | > 100ms | > 250ms |
| Pool Retrieval (All) | < 100ms | > 200ms | > 500ms |
| Configuration Update | < 200ms | > 500ms | > 1000ms |
| Statistics Query | < 300ms | > 500ms | > 1000ms |

### Throughput Targets

| Metric | Target | Maximum | Notes |
|--------|--------|---------|-------|
| Contributions per Second | 100+ | 500+ | With batch processing |
| Win Processing per Minute | 50+ | 200+ | Sequential processing |
| Concurrent Users | 1000+ | 5000+ | With proper scaling |
| Database Connections | 20-50 | 100 | Connection pooling |
| Cache Hit Rate | 90%+ | 95%+ | After warmup period |

## Database Performance Tuning

### PostgreSQL Configuration

#### Memory Settings

```sql
-- postgresql.conf optimal settings for jackpot service

-- Shared buffer pool (25% of available RAM)
shared_buffers = 256MB  # Adjust based on total RAM

-- Working memory per operation (4-16MB recommended)
work_mem = 8MB
maintenance_work_mem = 64MB

-- Effective cache size (75% of available RAM)
effective_cache_size = 768MB

-- WAL settings for performance
wal_buffers = 16MB
checkpoint_completion_target = 0.9
max_wal_size = 1GB
min_wal_size = 80MB
```

#### Connection Settings

```sql
-- postgresql.conf connection settings

-- Maximum connections (account for connection pooling)
max_connections = 100

-- Statement timeout (prevent runaway queries)
statement_timeout = 30s
idle_in_transaction_session_timeout = 10min

-- TCP keepalive settings
tcp_keepalives_idle = 600
tcp_keepalives_interval = 30
tcp_keepalives_count = 3
```

#### Query Optimization Settings

```sql
-- postgresql.conf query optimization

-- Enable query planner statistics
track_activities = on
track_counts = on
track_io_timing = on

-- Statement logging for analysis
log_statement = 'mod'  # Log data modifications
log_min_duration_statement = 1000  # Log queries > 1s

-- Checkpoint settings
checkpoint_timeout = 10min
checkpoint_completion_target = 0.9
```

### Database Index Optimization

#### Critical Indexes

```sql
-- Primary access pattern indexes
CREATE INDEX CONCURRENTLY idx_jackpots_group ON jackpots (group);
CREATE INDEX CONCURRENTLY idx_jackpots_version ON jackpots (version);
CREATE INDEX CONCURRENTLY idx_jackpots_last_modified ON jackpots (last_modified_at);

-- Composite indexes for common queries
CREATE INDEX CONCURRENTLY idx_jackpots_group_version ON jackpots (group, version);

-- Partial indexes for active jackpots
CREATE INDEX CONCURRENTLY idx_jackpots_active_groups 
ON jackpots (group) 
WHERE current_amount > 0;

-- JSONB indexes for history queries
CREATE INDEX CONCURRENTLY idx_jackpots_contribution_history_gin 
ON jackpots USING gin (contribution_history);

CREATE INDEX CONCURRENTLY idx_jackpots_win_history_gin 
ON jackpots USING gin (win_history);
```

#### Index Maintenance

```sql
-- Regular index maintenance
ANALYZE jackpots;

-- Reindex if fragmentation > 30%
REINDEX TABLE CONCURRENTLY jackpots;

-- Check index usage
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_stat_user_indexes 
WHERE schemaname = 'public' AND tablename = 'jackpots'
ORDER BY idx_scan DESC;

-- Identify unused indexes
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan
FROM pg_stat_user_indexes 
WHERE schemaname = 'public' 
    AND tablename = 'jackpots' 
    AND idx_scan = 0
ORDER BY indexname;
```

### Query Optimization

#### Optimized Query Patterns

```typescript
// Optimized jackpot queries
const optimizedQueries = {
  // Efficient batch pool retrieval
  getAllPools: `
    SELECT 
      group,
      current_amount,
      total_contributions,
      total_wins,
      last_won_amount,
      last_won_at,
      version,
      last_modified_at
    FROM jackpots 
    WHERE group IN ('minor', 'major', 'mega')
    ORDER BY group
  `,

  // Optimized contribution with single query
  contributeBatch: `
    UPDATE jackpots SET 
      current_amount = CASE 
        WHEN group = $1 THEN current_amount + $2
        WHEN group = $3 THEN current_amount + $4
        WHEN group = $5 THEN current_amount + $6
        ELSE current_amount
      END,
      total_contributions = CASE 
        WHEN group = $1 THEN total_contributions + $2
        WHEN group = $3 THEN total_contributions + $4
        WHEN group = $5 THEN total_contributions + $6
        ELSE total_contributions
      END,
      version = version + 1,
      updated_at = NOW(),
      last_modified_at = NOW()
    WHERE group IN ($1, $3, $5)
    RETURNING group, current_amount, total_contributions, version
  `,

  // Optimized win processing
  processWin: `
    WITH win_data AS (
      SELECT 
        $1::text as target_group,
        $2::numeric as win_amount,
        version,
        current_amount
      FROM jackpots 
      WHERE group = $1::text
      FOR UPDATE
    )
    UPDATE jackpots SET 
      current_amount = CASE 
        WHEN group = (SELECT target_group FROM win_data) 
        THEN GREATEST(0, current_amount - (SELECT win_amount FROM win_data))
        ELSE current_amount
      END,
      total_wins = CASE 
        WHEN group = (SELECT target_group FROM win_data) 
        THEN total_wins + (SELECT win_amount FROM win_data)
        ELSE total_wins
      END,
      last_won_amount = CASE 
        WHEN group = (SELECT target_group FROM win_data) 
        THEN (SELECT win_amount FROM win_data)
        ELSE last_won_amount
      END,
      last_won_at = CASE 
        WHEN group = (SELECT target_group FROM win_data) 
        THEN NOW()
        ELSE last_won_at
      END,
      version = version + 1,
      updated_at = NOW(),
      last_modified_at = NOW()
    WHERE group = $1::text
    RETURNING group, current_amount, total_wins, last_won_amount, version
  `
};
```

#### Query Analysis and Optimization

```sql
-- Enable query statistics
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Analyze slow queries
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    stddev_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
WHERE query LIKE '%jackpot%'
ORDER BY total_time DESC 
LIMIT 10;

-- Check for missing indexes
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM jackpots WHERE group = 'minor';

-- Analyze query plans
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT 
    group,
    current_amount,
    total_contributions
FROM jackpots 
WHERE group IN ('minor', 'major', 'mega')
ORDER BY group;
```

## Application Performance Tuning

### Connection Pool Configuration

```typescript
// Optimal connection pool settings
const dbConfig = {
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  
  // Connection pool settings
  min: 2,                           // Minimum connections
  max: parseInt(process.env.DB_POOL_MAX || '20'), // Maximum connections
  idleTimeoutMillis: 30000,         // Close idle connections after 30s
  connectionTimeoutMillis: 2000,    // Connection timeout
  
  // Health check settings
  allowExitOnIdle: false,
  keepAlive: true,
  keepAliveInitialDelayMillis: 10000,
  
  // Jackpot-specific optimizations
  application_name: 'jackpot-service',
  
  // SSL settings for production
  ssl: process.env.NODE_ENV === 'production' ? {
    rejectUnauthorized: false
  } : false,
};

// Connection pool monitoring
const pool = new Pool(dbConfig);

pool.on('connect', (client) => {
  console.log('New client connected');
});

pool.on('acquire', (client) => {
  console.log('Client acquired from pool');
});

pool.on('error', (err, client) => {
  console.error('Unexpected error on idle client', err);
});
```

### Caching Strategy

#### Multi-Level Caching

```typescript
// Level 1: In-memory cache (fastest)
class JackpotMemoryCache {
  private cache = new Map<string, CacheEntry>();
  private readonly ttl = 5000; // 5 seconds
  
  set(key: string, value: any): void {
    this.cache.set(key, {
      value,
      timestamp: Date.now(),
      expires: Date.now() + this.ttl
    });
  }
  
  get(key: string): any | null {
    const entry = this.cache.get(key);
    if (!entry) return null;
    
    if (Date.now() > entry.expires) {
      this.cache.delete(key);
      return null;
    }
    
    return entry.value;
  }
  
  invalidate(pattern: string): void {
    for (const key of this.cache.keys()) {
      if (key.includes(pattern)) {
        this.cache.delete(key);
      }
    }
  }
}

// Level 2: Redis cache (distributed)
class JackpotRedisCache {
  private redis: Redis;
  
  constructor() {
    this.redis = new Redis({
      host: process.env.REDIS_HOST,
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      retryDelayOnFailover: 100,
      maxRetriesPerRequest: 3,
    });
  }
  
  async set(key: string, value: any, ttl: number = 300): Promise<void> {
    await this.redis.setex(key, ttl, JSON.stringify(value));
  }
  
  async get(key: string): Promise<any | null> {
    const value = await this.redis.get(key);
    return value ? JSON.parse(value) : null;
  }
  
  async invalidate(pattern: string): Promise<void> {
    const keys = await this.redis.keys(`*${pattern}*`);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }
  }
}

// Level 3: Database cache (persistent)
class JackpotDBCache {
  async cacheJackpotPools(pools: Record<string, any>): Promise<void> {
    // Cache in database for recovery
    await db.insert(cacheTable).values({
      key: 'jackpot_pools',
      value: JSON.stringify(pools),
      expiresAt: new Date(Date.now() + 300000), // 5 minutes
    }).onConflictDoUpdate({
      target: cacheTable.key,
      set: {
        value: JSON.stringify(pools),
        expiresAt: new Date(Date.now() + 300000),
        updatedAt: new Date(),
      }
    });
  }
}
```

#### Cache-Aware Service Implementation

```typescript
class CacheAwareJackpotService {
  private memoryCache = new JackpotMemoryCache();
  private redisCache = new JackpotRedisCache();
  private dbCache = new JackpotDBCache();
  
  async getJackpotPools(): Promise<Record<string, any>> {
    const cacheKey = 'jackpot_pools_all';
    
    // Try memory cache first (fastest)
    let pools = this.memoryCache.get(cacheKey);
    if (pools) {
      return pools;
    }
    
    // Try Redis cache (fast, distributed)
    pools = await this.redisCache.get(cacheKey);
    if (pools) {
      this.memoryCache.set(cacheKey, pools);
      return pools;
    }
    
    // Query database
    pools = await this.queryDatabaseForPools();
    
    // Update all cache levels
    this.memoryCache.set(cacheKey, pools);
    await this.redisCache.set(cacheKey, pools, 300); // 5 minutes
    await this.dbCache.cacheJackpotPools(pools);
    
    return pools;
  }
  
  async invalidatePoolsCache(): Promise<void> {
    this.memoryCache.invalidate('jackpot_pools');
    await this.redisCache.invalidate('jackpot_pools');
  }
}
```

### Batch Processing Optimization

#### High-Throughput Batch Operations

```typescript
class JackpotBatchProcessor {
  private batchQueue: BatchContribution[] = [];
  private processing = false;
  private batchSize = 100;
  private flushInterval = 1000; // 1 second
  
  constructor() {
    // Periodic flush
    setInterval(() => {
      this.flushBatch();
    }, this.flushInterval);
  }
  
  async addContribution(contribution: BatchContribution): Promise<void> {
    this.batchQueue.push(contribution);
    
    if (this.batchQueue.length >= this.batchSize) {
      await this.flushBatch();
    }
  }
  
  private async flushBatch(): Promise<void> {
    if (this.processing || this.batchQueue.length === 0) {
      return;
    }
    
    this.processing = true;
    const batch = this.batchQueue.splice(0, this.batchSize);
    
    try {
      await this.processBatch(batch);
    } catch (error) {
      console.error('Batch processing failed:', error);
      // Re-queue failed contributions
      this.batchQueue.unshift(...batch);
    } finally {
      this.processing = false;
    }
  }
  
  private async processBatch(contributions: BatchContribution[]): Promise<void> {
    await db.transaction(async (tx) => {
      // Group contributions by jackpot group
      const groupedContributions = this.groupByGroup(contributions);
      
      // Process all groups in a single query
      for (const [group, groupContributions] of groupedContributions) {
        const totalContribution = groupContributions.reduce(
          (sum, contrib) => sum + contrib.amount, 0
        );
        
        await tx
          .update(jackpotTable)
          .set({
            currentAmount: sql`current_amount + ${totalContribution}`,
            totalContributions: sql`total_contributions + ${totalContribution}`,
            version: sql`version + 1`,
            updatedAt: new Date(),
          })
          .where(eq(jackpotTable.group, group));
      }
    });
  }
  
  private groupByGroup(contributions: BatchContribution[]): Map<string, BatchContribution[]> {
    const grouped = new Map<string, BatchContribution[]>();
    
    for (const contribution of contributions) {
      const groups = this.getGameJackpotGroups(contribution.gameId);
      
      for (const group of groups) {
        const amount = Math.floor(contribution.wagerAmount * this.getContributionRate(group));
        
        if (!grouped.has(group)) {
          grouped.set(group, []);
        }
        
        grouped.get(group)!.push({
          ...contribution,
          amount,
        });
      }
    }
    
    return grouped;
  }
}
```

### Memory Management

#### Memory-Efficient Data Processing

```typescript
class JackpotMemoryManager {
  private readonly maxMemoryUsage = 50 * 1024 * 1024; // 50MB
  private readonly batchSize = 1000;
  
  async processLargeDataset(dataset: AsyncIterable<JackpotData>): Promise<void> {
    let batch: JackpotData[] = [];
    let processedCount = 0;
    
    for await (const item of dataset) {
      batch.push(item);
      
      if (batch.length >= this.batchSize) {
        await this.processBatch(batch);
        processedCount += batch.length;
        
        // Check memory usage
        if (this.getMemoryUsage() > this.maxMemoryUsage) {
          await this.forceGarbageCollection();
        }
        
        batch = [];
      }
    }
    
    // Process remaining items
    if (batch.length > 0) {
      await this.processBatch(batch);
    }
    
    console.log(`Processed ${processedCount + batch.length} items`);
  }
  
  private getMemoryUsage(): number {
    return process.memoryUsage().heapUsed;
  }
  
  private async forceGarbageCollection(): Promise<void> {
    if (global.gc) {
      global.gc();
      await new Promise(resolve => setTimeout(resolve, 100));
    }
  }
  
  private async processBatch(batch: JackpotData[]): Promise<void> {
    // Process batch efficiently
    await this.batchProcessor.process(batch);
  }
}
```

## Performance Monitoring

### Real-Time Performance Metrics

```typescript
class JackpotPerformanceMonitor {
  private metrics = new Map<string, MetricCollector>();
  private alerts: AlertConfig[] = [];
  
  constructor() {
    this.initializeMetrics();
    this.startMonitoring();
  }
  
  private initializeMetrics(): void {
    // Response time metrics
    this.metrics.set('response_time_contribution', new ResponseTimeMetric());
    this.metrics.set('response_time_win', new ResponseTimeMetric());
    this.metrics.set('response_time_pool_query', new ResponseTimeMetric());
    
    // Throughput metrics
    this.metrics.set('contributions_per_second', new ThroughputMetric());
    this.metrics.set('wins_per_minute', new ThroughputMetric());
    
    // Resource metrics
    this.metrics.set('database_connections', new ResourceMetric());
    this.metrics.set('memory_usage', new ResourceMetric());
    
    // Error metrics
    this.metrics.set('error_rate', new ErrorRateMetric());
    this.metrics.set('timeout_rate', new ErrorRateMetric());
  }
  
  async recordContribution(duration: number, success: boolean): Promise<void> {
    this.metrics.get('response_time_contribution')!.record(duration);
    this.metrics.get('contributions_per_second')!.increment();
    
    if (!success) {
      this.metrics.get('error_rate')!.increment();
    }
    
    // Check thresholds
    if (duration > 200) {
      this.triggerAlert('HIGH_RESPONSE_TIME', { operation: 'contribution', duration });
    }
  }
  
  async recordWinProcessing(duration: number, success: boolean): Promise<void> {
    this.metrics.get('response_time_win')!.record(duration);
    this.metrics.get('wins_per_minute')!.increment();
    
    if (!success) {
      this.metrics.get('error_rate')!.increment();
    }
    
    if (duration > 300) {
      this.triggerAlert('HIGH_RESPONSE_TIME', { operation: 'win_processing', duration });
    }
  }
  
  getCurrentMetrics(): PerformanceMetrics {
    return {
      response_times: {
        contribution_p50: this.metrics.get('response_time_contribution')!.getP50(),
        contribution_p95: this.metrics.get('response_time_contribution')!.getP95(),
        contribution_p99: this.metrics.get('response_time_contribution')!.getP99(),
        win_p50: this.metrics.get('response_time_win')!.getP50(),
        win_p95: this.metrics.get('response_time_win')!.getP95(),
      },
      throughput: {
        contributions_per_second: this.metrics.get('contributions_per_second')!.getRate(),
        wins_per_minute: this.metrics.get('wins_per_minute')!.getRate(),
      },
      resources: {
        database_connections: this.metrics.get('database_connections')!.getCurrent(),
        memory_usage_mb: this.metrics.get('memory_usage')!.getCurrent() / 1024 / 1024,
      },
      errors: {
        error_rate: this.metrics.get('error_rate')!.getRate(),
        timeout_rate: this.metrics.get('timeout_rate')!.getRate(),
      }
    };
  }
  
  private triggerAlert(type: string, data: any): void {
    const alert: Alert = {
      type,
      severity: this.getSeverity(type, data),
      timestamp: new Date(),
      data,
    };
    
    this.sendAlert(alert);
  }
}
```

### Performance Dashboard

```typescript
// Real-time performance dashboard
class PerformanceDashboard {
  async generateReport(): Promise<string> {
    const metrics = await this.performanceMonitor.getCurrentMetrics();
    
    return `
# Jackpot Service Performance Report
Generated: ${new Date().toISOString()}

## Response Times
| Operation | P50 | P95 | P99 | Status |
|-----------|-----|-----|-----|--------|
| Contribution | ${metrics.response_times.contribution_p50}ms | ${metrics.response_times.contribution_p95}ms | ${metrics.response_times.contribution_p99}ms | ${this.getStatus(metrics.response_times.contribution_p95)} |
| Win Processing | ${metrics.response_times.win_p50}ms | ${metrics.response_times.win_p95}ms | ${metrics.response_times.win_p99}ms | ${this.getStatus(metrics.response_times.win_p95)} |

## Throughput
| Metric | Current Rate | Target | Status |
|--------|-------------|--------|--------|
| Contributions/sec | ${metrics.throughput.contributions_per_second} | 100+ | ${this.getThroughputStatus(metrics.throughput.contributions_per_second)} |
| Wins/minute | ${metrics.throughput.wins_per_minute} | 50+ | ${this.getThroughputStatus(metrics.throughput.wins_per_minute * 60)} |

## Resource Usage
| Resource | Current Usage | Threshold | Status |
|----------|---------------|-----------|--------|
| Database Connections | ${metrics.resources.database_connections} | 80% | ${this.getResourceStatus(metrics.resources.database_connections)} |
| Memory Usage | ${metrics.resources.memory_usage_mb}MB | 85% | ${this.getMemoryStatus(metrics.resources.memory_usage_mb)} |

## Error Rates
| Error Type | Rate | Threshold | Status |
|------------|------|-----------|--------|
| General Errors | ${metrics.errors.error_rate}% | 1% | ${this.getErrorStatus(metrics.errors.error_rate)} |
| Timeouts | ${metrics.errors.timeout_rate}% | 0.5% | ${this.getErrorStatus(metrics.errors.timeout_rate)} |
`;
  }
  
  private getStatus(value: number): string {
    if (value < 100) return '游릭 Good';
    if (value < 200) return '游리 Warning';
    return '游댮 Critical';
  }
  
  private getThroughputStatus(value: number): string {
    if (value >= 100) return '游릭 Good';
    if (value >= 50) return '游리 Warning';
    return '游댮 Critical';
  }
}
```

## Optimization Strategies

### Database Query Optimization

#### Index Strategy

```sql
-- Analyze query patterns and create appropriate indexes
-- Monitor index usage and remove unused indexes

-- For high-frequency queries
CREATE INDEX CONCURRENTLY idx_jackpots_group_current_amount 
ON jackpots (group, current_amount) 
WHERE current_amount > 0;

-- For timestamp-based queries
CREATE INDEX CONCURRENTLY idx_jackpots_last_modified 
ON jackpots (last_modified_at DESC);

-- Composite indexes for complex queries
CREATE INDEX CONCURRENTLY idx_jackpots_group_version_amount 
ON jackpots (group, version, current_amount);
```

#### Query Plan Optimization

```sql
-- Use EXPLAIN ANALYZE to understand query performance
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT 
    group,
    current_amount,
    total_contributions
FROM jackpots 
WHERE group IN ('minor', 'major', 'mega')
ORDER BY group;

-- Optimize with proper indexes and query structure
-- Consider using materialized views for complex aggregations
CREATE MATERIALIZED VIEW jackpot_statistics AS
SELECT 
    group,
    COUNT(*) as total_transactions,
    SUM(current_amount) as total_amount,
    AVG(current_amount) as avg_amount,
    MAX(last_modified_at) as last_update
FROM jackpots 
GROUP BY group;

-- Refresh materialized view periodically
CREATE INDEX ON jackpot_statistics (group);
```

### Application-Level Optimization

#### Connection Pool Tuning

```typescript
// Dynamic connection pool adjustment
class AdaptiveConnectionPool {
  private pool: Pool;
  private targetUtilization = 0.7;
  
  async adjustPoolSize(): Promise<void> {
    const stats = this.pool.getPoolStats();
    const utilization = stats.used / stats.total;
    
    if (utilization > this.targetUtilization && stats.total < 50) {
      // Increase pool size
      await this.pool.expand(5);
    } else if (utilization < 0.3 && stats.total > 10) {
      // Decrease pool size
      await this.pool.shrink(5);
    }
  }
  
  getOptimalPoolSize(currentLoad: number): number {
    // Calculate optimal pool size based on load
    const baseSize = 5;
    const loadBasedSize = Math.ceil(currentLoad / 100);
    return Math.min(Math.max(baseSize, loadBasedSize), 50);
  }
}
```

#### Memory Optimization

```typescript
// Memory-efficient data structures
class OptimizedJackpotStore {
  private pools = new Map<string, JackpotPool>();
  private accessLog: AccessEntry[] = [];
  private readonly maxLogSize = 1000;
  
  // Use object pooling for frequent allocations
  private poolAllocator = new ObjectPool(() => ({
    group: '',
    amount: 0,
    timestamp: new Date(),
  }));
  
  getPool(group: string): JackpotPool | null {
    const pool = this.pools.get(group);
    
    if (pool) {
      // Log access for LRU cache optimization
      this.logAccess(group);
      
      // Periodically clean up old access logs
      if (this.accessLog.length > this.maxLogSize) {
        this.accessLog.splice(0, this.maxLogSize / 2);
      }
    }
    
    return pool || null;
  }
  
  private logAccess(group: string): void {
    this.accessLog.push({
      group,
      timestamp: Date.now(),
    });
  }
  
  // LRU cache for frequently accessed data
  private lruCache = new Map<string, any>();
  private readonly cacheSize = 100;
  
  getCachedData(key: string): any {
    if (this.lruCache.has(key)) {
      // Move to end (most recently used)
      const value = this.lruCache.get(key);
      this.lruCache.delete(key);
      this.lruCache.set(key, value);
      return value;
    }
    
    return null;
  }
  
  setCachedData(key: string, value: any): void {
    if (this.lruCache.size >= this.cacheSize) {
      // Remove least recently used
      const firstKey = this.lruCache.keys().next().value;
      this.lruCache.delete(firstKey);
    }
    
    this.lruCache.set(key, value);
  }
}
```

## Load Testing and Validation

### Load Testing Framework

```typescript
class JackpotLoadTester {
  private results: LoadTestResult[] = [];
  
  async runLoadTest(config: LoadTestConfig): Promise<LoadTestReport> {
    const { duration, concurrentUsers, operations } = config;
    
    console.log(`Starting load test: ${concurrentUsers} users for ${duration}ms`);
    
    const startTime = Date.now();
    const endTime = startTime + duration;
    
    const promises: Promise<void>[] = [];
    
    // Create concurrent user simulations
    for (let i = 0; i < concurrentUsers; i++) {
      promises.push(this.simulateUser(i, startTime, endTime, operations));
    }
    
    // Wait for all users to complete
    await Promise.allSettled(promises);
    
    // Analyze results
    return this.analyzeResults();
  }
  
  private async simulateUser(userId: number, startTime: number, endTime: number, operations: OperationConfig): Promise<void> {
    while (Date.now() < endTime) {
      for (const operation of operations) {
        const startOperationTime = Date.now();
        
        try {
          switch (operation.type) {
            case 'contribution':
              await this.testContribution(operation);
              break;
            case 'win':
              await this.testWin(operation);
              break;
            case 'pool_query':
              await this.testPoolQuery(operation);
              break;
          }
          
          const duration = Date.now() - startOperationTime;
          this.recordResult({
            userId,
            operation: operation.type,
            duration,
            success: true,
            timestamp: startOperationTime,
          });
          
        } catch (error) {
          this.recordResult({
            userId,
            operation: operation.type,
            duration: Date.now() - startOperationTime,
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            timestamp: startOperationTime,
          });
        }
        
        // Wait between operations
        await this.delay(operation.interval);
      }
    }
  }
  
  private async testContribution(config: OperationConfig): Promise<void> {
    const result = await processJackpotContribution('load_test_game', 1000);
    if (!result.success) {
      throw new Error(`Contribution failed: ${result.error}`);
    }
  }
  
  private async testWin(config: OperationConfig): Promise<void> {
    const groups = ['minor', 'major', 'mega'] as const;
    const randomGroup = groups[Math.floor(Math.random() * groups.length)];
    
    const result = await processJackpotWin(randomGroup, 'load_test_game', 'test-user-123', 500);
    if (!result.success) {
      throw new Error(`Win processing failed: ${result.error}`);
    }
  }
  
  private async testPoolQuery(config: OperationConfig): Promise<void> {
    const pools = await getJackpotPools();
    if (!pools || Object.keys(pools).length === 0) {
      throw new Error('No pools returned');
    }
  }
  
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  private recordResult(result: LoadTestResult): void {
    this.results.push(result);
  }
  
  private analyzeResults(): LoadTestReport {
    const successful = this.results.filter(r => r.success);
    const failed = this.results.filter(r => !r.success);
    
    const durations = successful.map(r => r.duration);
    durations.sort((a, b) => a - b);
    
    const totalOperations = this.results.length;
    const successfulOperations = successful.length;
    const failedOperations = failed.length;
    
    return {
      summary: {
        totalOperations,
        successfulOperations,
        failedOperations,
        successRate: (successfulOperations / totalOperations) * 100,
        averageResponseTime: durations.reduce((a, b) => a + b, 0) / durations.length,
        minResponseTime: Math.min(...durations),
        maxResponseTime: Math.max(...durations),
        p50ResponseTime: this.calculatePercentile(durations, 50),
        p95ResponseTime: this.calculatePercentile(durations, 95),
        p99ResponseTime: this.calculatePercentile(durations, 99),
      },
      operations: this.groupResultsByOperation(),
      errors: failed.map(f => ({ operation: f.operation, error: f.error })),
    };
  }
  
  private calculatePercentile(values: number[], percentile: number): number {
    const index = Math.ceil((percentile / 100) * values.length) - 1;
    return values[Math.max(0, index)];
  }
  
  private groupResultsByOperation(): Record<string, OperationStats> {
    const grouped = this.results.reduce((acc, result) => {
      if (!acc[result.operation]) {
        acc[result.operation] = [];
      }
      acc[result.operation].push(result);
      return acc;
    }, {} as Record<string, LoadTestResult[]>);
    
    const stats: Record<string, OperationStats> = {};
    
    for (const [operation, results] of Object.entries(grouped)) {
      const successful = results.filter(r => r.success);
      const durations = successful.map(r => r.duration);
      
      stats[operation] = {
        totalRequests: results.length,
        successfulRequests: successful.length,
        failedRequests: results.length - successful.length,
        averageResponseTime: durations.reduce((a, b) => a + b, 0) / durations.length,
        p50ResponseTime: this.calculatePercentile(durations, 50),
        p95ResponseTime: this.calculatePercentile(durations, 95),
        p99ResponseTime: this.calculatePercentile(durations, 99),
      };
    }
    
    return stats;
  }
}
```

### Performance Benchmarking

```typescript
// Automated performance benchmarking
class PerformanceBenchmark {
  async runBenchmarks(): Promise<BenchmarkReport> {
    console.log('游 Starting performance benchmarks...');
    
    const benchmarks = [
      this.benchmarkContributions(),
      this.benchmarkWinProcessing(),
      this.benchmarkPoolQueries(),
      this.benchmarkConcurrentOperations(),
      this.benchmarkMemoryUsage(),
      this.benchmarkDatabasePerformance(),
    ];
    
    const results = await Promise.all(benchmarks);
    
    return {
      timestamp: new Date().toISOString(),
      benchmarks: results,
      summary: this.generateBenchmarkSummary(results),
    };
  }
  
  private async benchmarkContributions(): Promise<BenchmarkResult> {
    const iterations = 1000;
    const durations: number[] = [];
    
    for (let i = 0; i < iterations; i++) {
      const start = performance.now();
      
      await processJackpotContribution('benchmark_game', 1000);
      
      durations.push(performance.now() - start);
      
      // Small delay to avoid overwhelming the system
      if (i % 100 === 0) {
        await new Promise(resolve => setTimeout(resolve, 10));
      }
    }
    
    return {
      name: 'Jackpot Contributions',
      iterations,
      averageTime: this.calculateAverage(durations),
      minTime: Math.min(...durations),
      maxTime: Math.max(...durations),
      p95Time: this.calculatePercentile(durations, 95),
      p99Time: this.calculatePercentile(durations, 99),
      throughputPerSecond: 1000 / this.calculateAverage(durations),
    };
  }
  
  private async benchmarkConcurrentOperations(): Promise<BenchmarkResult> {
    const concurrentOperations = 100;
    const iterations = 10;
    const durations: number[] = [];
    
    for (let i = 0; i < iterations; i++) {
      const start = performance.now();
      
      const promises = Array.from({ length: concurrentOperations }, (_, index) =>
        processJackpotContribution(`concurrent_game_${index}`, 1000)
      );
      
      await Promise.allSettled(promises);
      
      durations.push(performance.now() - start);
    }
    
    return {
      name: 'Concurrent Operations',
      iterations,
      concurrentUsers: concurrentOperations,
      averageTime: this.calculateAverage(durations),
      minTime: Math.min(...durations),
      maxTime: Math.max(...durations),
      p95Time: this.calculatePercentile(durations, 95),
      throughput: (concurrentOperations * iterations) / this.calculateAverage(durations) * 1000,
    };
  }
  
  private calculateAverage(values: number[]): number {
    return values.reduce((sum, val) => sum + val, 0) / values.length;
  }
  
  private calculatePercentile(values: number[], percentile: number): number {
    const sorted = [...values].sort((a, b) => a - b);
    const index = Math.ceil((percentile / 100) * sorted.length) - 1;
    return sorted[Math.max(0, index)];
  }
}
```

## Performance Optimization Checklist

### Database Optimization

- [ ] **Connection Pool Tuning**: Optimal pool size based on load
- [ ] **Index Optimization**: Proper indexes for query patterns
- [ ] **Query Optimization**: Use EXPLAIN ANALYZE for slow queries
- [ ] **Memory Settings**: Configure shared_buffers and work_mem
- [ ] **WAL Settings**: Optimize for write performance
- [ ] **Statistics**: Keep table statistics up to date

### Application Optimization

- [ ] **Caching Strategy**: Multi-level caching implementation
- [ ] **Batch Processing**: Group operations for efficiency
- [ ] **Memory Management**: Prevent memory leaks and optimize GC
- [ ] **Connection Management**: Proper connection lifecycle
- [ ] **Error Handling**: Efficient error handling and recovery
- [ ] **Resource Monitoring**: Track resource usage patterns

### Monitoring and Alerting

- [ ] **Performance Metrics**: Response time, throughput, error rates
- [ ] **Resource Monitoring**: CPU, memory, database connections
- [ ] **Alerting**: Threshold-based alerts for performance degradation
- [ ] **Dashboards**: Real-time performance visualization
- [ ] **Log Analysis**: Performance issue detection in logs
- [ ] **Automated Testing**: Regular performance regression testing

### Load Testing and Validation

- [ ] **Load Testing**: Regular load testing with realistic scenarios
- [ ] **Stress Testing**: Test system limits and breaking points
- [ ] **Performance Baselines**: Establish and maintain performance benchmarks
- [ ] **Capacity Planning**: Plan for future growth and scaling
- [ ] **Performance Monitoring**: Continuous performance tracking
- [ ] **Optimization Cycle**: Regular performance review and optimization

---

*This performance tuning guide should be regularly updated based on monitoring data and performance analysis. Regular reviews ensure continued optimal performance.*